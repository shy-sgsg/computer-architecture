# 计算机体系结构期末复习
</br></br>

## L1-课程概要与体系结构基础

### 硬件组成与架构发展
- **不同类型计算机硬件组成**
    - **个人计算机**：以联想 ThinkCentre M8300t 台式机为例，其主机箱内包含多种 PCIe 外设插卡、内存条 DIMM、主板及内存插槽、数据线缆、中央处理器 CPU（风扇及散热片覆盖）、机械硬盘 HDD、电源模块 Power Supply、固态硬盘 SSD 及供电线缆等。这些组件协同工作，实现计算机的基本功能，如数据存储、处理和传输。
    - **高性能计算机（服务器）**：如华为 RH2285 型号机架式服务器，内部有两颗高性能 CPU（散热片覆盖）、主板、内存条 DIMM 及内存插槽、扩展板卡（PCIe FPGA）、风扇、磁盘阵列等。由于服务器需要提供高性能的计算、存储等服务，所以在稳定性、可靠性、安全性、可扩展性、可管理性等方面有较高要求，其硬件配置和架构设计都围绕这些需求展开。
    - **单板计算机（YSYX 单板计算机）**：包含 SoC 芯片、按键、选择开关、各种接口（如 FPGA JTAG 接口、外设切换开关、PL VGA、PL PS/2、PLIO 等）、晶振插座、电源模块（如电源 LDO、电源指示 LED）、烧写器切换、电平转换芯片、PS PMOD 扩展、耳机输出、音频输入、复位按键、时钟拨码开关、TF 卡插座、板载烧写器、Flash 插座、SoC UART 等众多组件。这些组件集成在一块单板上，适用于一些特定的应用场景，如嵌入式系统开发等。
- **计算机发展历程中的重要机型**
    - **ENIAC**：世界第一台电子计算机，于 1946 年诞生。它采用手动编程，通过设置开关、连接插头和插座、插拔电缆来实现程序控制。每位数值采用十进制表示，乘法运算速度为 357 次/秒，除法为 38 次/秒，有 20 个 10 位寄存器（无存储器），加法速度达 5000 次/秒。一个十进制数用 10 个电子管表示，由 40 个 9 英尺（2.74 米）高机柜组成，占地面积 167 平方米，重达 30 吨，功耗 150KW，还包含 70000 个电阻、10000 个电容、17468 个电子管、6000 个手动开关、1500 个继电器和 500 万个焊点。其设计上的不足促使了后续计算机技术的改进和发展。
    - **中国的 103 机**：中国第一台通用数字电子计算机，诞生于 1958 年。它在我国计算机发展历程中具有重要意义，标志着我国在计算机领域的起步和探索，为后续计算机技术的研究和应用奠定了基础。
    - **长城 0520C - H 台式电脑**：中国第一台国产微型计算机，于 1985 年推出，是中国计算机发展的重要里程碑，推动了计算机在国内的普及和应用。
- **冯·诺依曼结构**
    - **组成部件**：由<font color=red> 运算器、控制器、存储器、输入设备和输出设备</font>五个基本部件组成。运算器负责进行算术和逻辑运算；控制器控制计算机各部件协调工作，自动执行指令；存储器用于存放数据和指令；输入设备如键盘、鼠标等用于向计算机输入信息；输出设备如显示器、打印机等用于输出计算机处理结果。
    - **工作方式**：采用“存储程序”工作方式，即将程序和数据以二进制形式存放在存储器中，计算机在运行时自动从存储器中逐条取出指令并执行。这种工作方式使得计算机的操作更加自动化和高效，成为现代计算机的基本工作原理。
    - **主要思想**：计算机内部以二进制表示指令和数据，每条指令由操作码和地址码两部分组成。操作码指出操作类型，地址码指出操作数的地址。存储器不仅能存放数据，还能存放指令，且计算机能够区分数据和指令。控制器能自动执行指令，运算器能进行加、减、乘、除等基本算术运算及一些逻辑运算和附加运算，操作人员通过输入输出设备与主机通信。

### 性能评估与定律
- **计算机硬件技术指标**
    - **机器字长**：CPU 一次能处理数据的位数，与 CPU 中的寄存器位数有关。例如，32 位 CPU 的机器字长为 32 位，它决定了计算机在一次运算中能够处理的数据量和精度，较长的机器字长通常能提高计算效率和精度，但也会增加硬件成本和复杂性。
    - **主频**：数字硬件的操作由恒定速率时钟控制，主频决定了 CPU 的时钟周期频率。例如，4.0GHz 的主频意味着 CPU 每秒可以执行 4.0×10⁹ 个时钟周期。主频越高，CPU 在单位时间内可以执行的操作次数越多，但过高的主频也可能带来散热等问题，并且主频的提升并非无限制地提高计算机性能，还受到其他因素的制约。
    - **运算速度**：包括<font color=red> CPI（Cycles per Instruction，执行一条指令所需时钟周期数）、IPC（Instructions per Cycle，一个周期内执行的指令数）、MIPS（每秒执行百万条指令）和 FLOPS（每秒浮点运算次数）</font>等指标。这些指标从不同角度衡量了计算机的运算能力，例如 MIPS 常用于衡量整数运算速度，而 FLOPS 则更侧重于浮点运算性能。在实际应用中，不同的应用场景对运算速度的不同方面有不同的需求，如科学计算更关注 FLOPS，而一般的办公应用则对 MIPS 较为敏感。
- **影响计算机及集成电路发展的定律**
    - **摩尔定律**：由 Gordon Moore 提出，集成电路上可容纳的晶体管数目约每隔两年便会增加一倍，同时成本仅有极小幅度的上升。这一定律在过去几十年间一直是计算机和集成电路行业发展的重要指导原则，促使芯片性能不断提升，推动了计算机技术的快速发展，使得计算机在体积不断缩小的同时，性能得到极大提高，如个人电脑从早期的大型机逐渐演变为如今的轻薄笔记本和小型台式机。
    - **登纳德缩放比例定律**：由 Robert H. Dennard 提出，即使在集成电路芯片上放置更多的电路，冷却问题基本不变，即功耗密度保持恒定。这一定律在集成电路设计中具有重要意义，使得芯片制造商在提高芯片集成度的同时，能够较好地控制功耗，为计算机性能的提升提供了支持。但随着技术的进一步发展，该定律在一定程度上受到了挑战，如在芯片制程进入纳米级别后，漏电等问题导致功耗难以按照该定律继续保持稳定。
    - **阿姆达尔定律**：关注系统性能提升的短板问题。它指出通过使用某种较快的执行方式所获得的性能提高，受可使用这种较快执行方式的时间所占的百分比例的限制，即通过更快的处理器来获得加速会受到慢的系统组件的制约。例如，在一个应用程序中，如果只有部分代码能够并行执行，即使增加处理器核心数量，整体性能的提升也会受到不能并行部分的限制。该定律在计算机系统设计和性能优化中具有重要指导作用，提醒设计者在提升系统性能时要综合考虑各个组件的性能平衡。
    ![alt text](image.png)

### 数的表示与运算
- **数的表示方法**
    - **无符号数**：寄存器的每一位均可存放数值，对于 n 位寄存器，其表示范围为[0, 2ⁿ - 1]。例如，8 位无符号数的表示范围是 0 到 255，16 位无符号数的表示范围是 0 到 65535。无符号数在一些不需要表示负数的场景中使用，如存储内存地址、计数等。
    - **有符号数**
        - **真值与机器数**：真值是带符号的数，而机器数是符号数字化的数。例如，+0.1011 和 -1100 是真值，而 0 1011 和 1 1100 是对应的机器数（这里以某种假设的表示方式为例），其中最高位为符号位，0 表示正数，1 表示负数。
        - **原码表示法**：对于整数，当 2ⁿ > x ≥ 0 时，[x]原 = 0,x；当 0 ≥ x > -2ⁿ 时，[x]原 = 2ⁿ - x。例如，x = +1110 时，[x]原 = 0,1110；x = -1110 时，[x]原 = 2⁴ + 1110 = 1,1110。原码表示法简单直观，但在进行加减运算时较为复杂，需要考虑符号位的处理。
        - **补码定义**：当 2ⁿ > x ≥ 0 时，[x]补 = 0,x；当 0 > x ≥ -2ⁿ（mod 2ⁿ + 1）时，[x]补 = 2ⁿ + 1 + x。例如，x = +1010 时，[x]补 = 0,1010；x = -1011000 时，[x]补 = 2⁷ + 1 + (-1011000) = 10000000 - 1011000 = 1,0101000。求补码的快捷方式是当真值为负时，补码可用原码除符号位外每位取反，末位加 1 求得。补码在计算机运算中具有重要作用，它使得减法运算可以转化为加法运算，简化了硬件设计。
- **算术逻辑单元（ALU）**
    - **功能与指令关系**：ALU 是指令执行的关键部分，负责执行算术和逻辑运算。在 MIPS32 指令集中，不同的指令如 lw（load word）、sw（store word）、beq（branch on equal）、slt（set on less than）等会触发 ALU 执行相应的操作，如加法、减法、逻辑与、逻辑或等。例如，执行 lw 指令时，ALU 可能需要计算内存地址，涉及加法操作；执行 beq 指令时，ALU 要进行相等比较，可能涉及减法操作并判断结果是否为 0。
    - **设计与内部结构**：以 32 位 ALU 为例，它可以由多个 1 位 ALU 组成。1 位 ALU 可以执行 AND、OR、ADD 等基本操作，通过进位链（CarryIn 和 CarryOut）连接各个 1 位 ALU 实现 32 位数据的运算。在进行减法运算时，通过对减数进行求补操作（按位取反并加 1）来实现，同时要注意区分有符号数和无符号数运算时溢出和进借位标志的处理。
    - **溢出和零检测逻辑**：对于溢出检测，在 N 位 ALU 中，<font color=red>Overflow = CarryIn[N - 1] XOR CarryOut[N - 1]</font>，即当最高有效位的进位输入和进位输出不同时，表示发生了溢出。对于零检测逻辑，通过将所有输出位进行或运算后取反来判断结果是否为 0，若结果为 0，则表示运算结果为 0。这些检测逻辑在保证运算准确性和程序控制流程中起到重要作用，例如在条件分支指令中，根据运算结果是否为 0 来决定是否进行分支跳转。
    - **Slt:Set-on-less-than**：<font color=red>做减法，最高符号位与 Overflow 进行异或操作之后供给最低位 ALU 的 Less 输入端</font>
    - 溢出标志 Overflow 表示有符号数加减法操作结果是否超出范围/结果的符号是否符合预期，进借位标志 CarryOut 表示无符号数加减法操作结果是否超出范围/结果能否完整地保存

### 指令系统相关
- **机器指令与指令系统概念**：机器指令是每一条机器语言的语句，而指令系统是所有机器指令的集合。指令系统处在软/硬件交界面，它既被硬件设计者用于设计计算机硬件，确保硬件能够正确执行指令；又被系统程序员看到，系统程序员需要依据指令系统编写汇编程序，并且只有熟悉计算机硬件实现才能写出高效代码。指令系统的设计好坏直接影响计算机的性能和成本，例如一个设计良好的指令系统可以提高程序的执行效率，减少指令执行的时间和硬件资源的消耗；而不合理的指令系统可能导致程序复杂、执行效率低下。
- **冯·诺依曼结构机器指令规定**：指令用二进制表示，和数据一起存放在主存中。指令由操作码和操作数（或其地址码）两部分组成，操作码定义操作类型，操作数（或其地址码）指示操作源和/或目的地。例如，在一个简单的加法指令中，操作码可能表示加法操作，操作数地址码则指定要相加的两个数在内存中的位置。这种规定使得计算机能够按照预定的程序逻辑自动执行指令，实现各种计算任务。
- **数据存储与寻址方式**
    - **数据存储顺序**：包括小端方式（Little Endian）和大端方式（Big Endian）。小端方式下，LSB（最低有效位）所在的地址是数的地址，即字地址或数的地址上存放数据的 LSB；大端方式下，MSB（最高有效位）所在的地址是数的地址，字地址或数的地址上存放数据的 MSB。例如，对于整数 -65535，在内存中存储时，若采用小端方式，其 4 个字节的存储顺序为[01 FF FF FF]（从低地址到高地址）；若采用大端方式，则存储顺序为[FF FF FF 01]。有些机器两种方式都支持，可通过特定控制位来设定采用哪种方式，如 ARM、MIPS 等。不同的数据存储顺序在数据传输和处理过程中可能会产生影响，特别是在多字节数据的处理和网络通信中需要特别注意。
    - **寻址方式**：包括立即寻址、直接寻址、间接寻址、寄存器寻址、寄间接寻址、偏移寻址、堆栈寻址等。立即寻址的操作数直接包含在指令中，执行速度快但操作数幅值有限；直接寻址的有效地址等于指令中的地址码，计算简单但地址范围有限；间接寻址通过地址码指向的内存单元获取操作数地址，地址范围大但需要多次存储器访问；寄存器寻址的操作数在寄存器中，指令执行快且指令短，但寄存器数量有限导致地址范围有限；寄间接寻址结合了寄存器和间接寻址的特点，地址范围大但需要额外的存储器访问；偏移寻址通过寄存器内容和偏移量计算有效地址，较为灵活但计算相对复杂；堆栈寻址以栈顶为有效地址，指令短但应用场景有限。这些寻址方式为程序员提供了多种访问数据的手段，在编写程序时可以根据数据的特点和程序的需求选择合适的寻址方式，以提高程序的性能和效率。
    ![alt text](image-1.png)
- **MIPS 指令系统**
    - **指令格式**：MIPS 指令长度为 32 位，有三种典型格式，即 R - type、I - type 和 J - type。R - type 格式包含 6 位操作码（op）、5 位源寄存器（rs）、5 位目标寄存器（rd）、5 位位移量（shamt）和 6 位功能码（funct），用于执行如加法（add）、减法（sub）、逻辑与（and）、逻辑或（or）、小于设置（slt）等操作；I - type 格式包含 6 位操作码、5 位源寄存器、5 位目标寄存器和 16 位立即数，用于数据传输和条件分支指令，如 lw（load word）、sw（store word）、beq（branch on equal）等；J - type 格式包含 6 位操作码和 26 位目标地址，用于无条件跳转指令。
    - **寄存器设置**：MIPS32 架构定义了 32 个 32 位通用目的寄存器（GPRs），编号从 r0 到 r31，其中 r0 硬连线为 0。还有一对特殊用途寄存器 HI 和 LO，用于保存整数乘法、除法和乘加运算的结果。此外，还有程序计数器 PC，它不是架构可见寄存器，但在指令执行过程中起到关键作用，指示下一条要执行的指令地址。这些寄存器的设置为指令的执行提供了数据存储和操作的空间，不同的寄存器在不同的指令和运算中发挥着特定的作用，合理使用寄存器可以提高程序的执行效率。 
</br>

## L2-复杂流水线和乱序执行(上)
该文档围绕计算机体系结构中处理器相关知识展开，涵盖了从基础概念到不同类型处理器设计，再到流水线处理器关键问题及解决方法等内容，是计算机体系结构课程的重要学习资料。
1. **计算机体系结构基础与简易处理器设计**
    - **基础回顾**：包括冯·诺依曼结构运行机理、程序计数器作用、计算机性能评估、数的表示及运算、指令系统等内容，这些构成了后续处理器设计的理论基石。
    - **MIPS 寄存器与指令**：MIPS 寄存器有 zero、at、v0 - v1 等多种类型，各自具有特定功能，如 zero 恒为 0，at 为汇编程序保留等。要实现的指令涵盖算术逻辑（add、sub、and、or、slt）、控制流（beq）、存储器引用（lw、sw）等类型，且这些指令在执行过程中都需使用 ALU。
2. **处理器通用机制与部件详解**
    - **通用机制步骤**：处理器首先利用程序计数器提供指令地址，接着从内存获取指令，随后依据指令精确控制寄存器的读写以及操作的执行，这一系列步骤是处理器工作的基本流程。
    - **部件功能特性**
        - **组合部件**：像与门（$Y = A \& B$）、加法器（$Y = A + B$）、多路复用器（$Y = S? I1 : I0$）、算术逻辑单元（$Y = F(A, B)$）等，其输出是输入的函数，部分组合部件的操作受时钟信号控制，在数字电路中发挥着关键作用。
        - **存储部件**：寄存器具有 N 位输入输出和写使能端，写使能信号控制数据写入，仅在时钟上升沿且写使能为 1 时更新。寄存器堆由 32 个寄存器组成，通过地址选择进行读写操作，内部通过一对多路复用器实现双读端口功能。内存有读写数据和地址总线，写操作受时钟影响，读操作在地址有效后经过短暂访问时间即可获得有效数据，类似组合逻辑。
3. **单周期处理器执行与数据通路剖析**
    - **指令执行流程**：以 add 加法指令为例，详细展示了在单周期处理器中的执行过程，包括从程序计数器获取指令地址，从寄存器堆读取操作数，经 ALU 运算后将结果写回寄存器堆等一系列操作，涉及到程序计数器更新、寄存器读写、ALU 运算和数据存储等关键步骤。
    - **各类指令通路**：分别深入介绍了 Reg - Reg 操作（如 add rd, rs, rt）、Load 操作（如 lw rt, rs, imm16）、Store 操作（如 sw rt, rs, imm16）、Branch 操作（如 beq rs, rt, imm16）和 Jump 指令的数据通路及相应控制信号。在 Branch 操作中，需读寄存器、比较操作数、计算目标地址等，控制信号由指令译码决定，如根据指令类型确定 ALU 操作、寄存器写使能、数据存储等控制信号的取值。
4. **单周期处理器控制器设计方法**
    - **译码表构建**：根据每条指令的功能，仔细分析控制信号的取值，并系统地在指令译码表中列出。例如，对于 R - format 指令，RegDst 为 1，ALUSrc 为 0 等，通过这种方式明确不同指令与控制信号之间的对应关系。
    - **逻辑表达式生成**：依据列出的指令和控制信号关系，运用逻辑推理和电路设计知识，写出每个控制信号的逻辑表达式。在 ALU 控制中，采用多层解码方式，根据 opcode 和 function code 对 ALU 操作进行解码，如 00 对应 lw、sw 的 add 操作，01 对应 beq 的 subtract 操作等，这种多层解码有助于减小主控单元规模、提高控制速度，从而优化控制器设计。
5. **多周期处理器设计要点**
    - **设计动机与优势**：为解决单周期 CPU 因最长指令周期决定时钟周期而导致的效率问题，多周期 CPU 将指令执行分解为多个较小任务，每个任务占用一个时钟周期，不同指令所需周期数不同，且可复用功能单元，如 ALU 和内存，有效提高了硬件资源的利用率。
    - **结构与控制实现**：在结构上，多周期 CPU 使用单一内存单元处理指令和数据，采用单一 ALU，并在主要功能单元后添加寄存器暂存输出结果，直到后续时钟周期使用。其控制单元通过有限状态机（FSM）实现，包括取指、译码、执行等多个状态，状态转换基于输入和当前状态，控制信号输出大多依赖当前状态（如 Moore FSM），这种设计方式能够灵活地控制指令执行流程，提高处理器的适应性和效率。
6. **处理器设计步骤与资源利用分析**
    - **设计步骤概述**：在确定指令集架构（ISA）后，处理器设计依次经过以下关键步骤：首先用 RTL（Register Transfer Language）详细分析每条指令的功能；接着根据指令功能确定所需元件并规划时钟方案；然后将数据通路进行互连，构建起数据传输的通道；再确定每个元件所需控制信号的取值，并汇总形成指令与控制信号关系表；最后依据该表得出每个控制信号的逻辑表达式，进而设计出控制器电路。在这个过程中，涉及到数据通路和控制器的设计，数据通路包含操作元件（由组合逻辑电路实现）和存储（状态）元件（由时序逻辑电路实现），两者相互协作，共同完成处理器的功能。
    - **资源利用对比**：在资源利用方面，单周期 CPU 以最长的 Load 指令执行时间确定时钟周期，当执行其他短指令时，在时钟周期后半阶段会整体处于闲置状态，造成硬件资源浪费。多周期 CPU 内部部件并非在每一拍都处于忙碌状态，存在一定的空闲时间。相比之下，流水线 CPU 旨在提高吞吐量和硬件资源利用率，但在实际应用中，由于指令执行的复杂性，难以达到理想的流水线状态，存在如指令执行阶段不均衡、资源冲突等问题，需要进一步的优化和改进。
7. **流水线处理器核心知识**
    - **理想与实际流水线**：理想流水线的目标是在增加少量成本（主要是硬件成本）的情况下显著提高吞吐量，其特点是重复相同且独立的操作，并且这些操作可均匀划分为无资源共享的子操作。然而，在实际的指令流水线中，由于指令的多样性和复杂性，难以满足这些理想条件。实际流水线中，非流水线版本和 k - stage 流水线版本的吞吐量受寄存器延迟影响，成本随寄存器数量增加而增加，如非流水线版本的吞吐量公式为 $BW = 1 /(T + S)$（$S$为寄存器延迟），k - stage 流水线版本为 $BW_{k - stage}=1 /(T / k + S)$；成本方面，非流水线版本为 $Cost = G + R$（$R$为寄存器成本），k - stage 流水线版本为 $Cost_{k - stage}=G + Rk$。
    - **设计问题与停顿原因**：流水线处理器设计面临诸多挑战，需要平衡各阶段工作，确保每个阶段的工作量和执行时间合理。同时，要妥善处理数据、控制和资源依赖问题，例如数据依赖包括 Flow 依赖（真数据依赖，即写后读 RAW）、Anti 依赖（读后写 WAR）和 Output 依赖（写后写 WAW），其中 Flow 依赖必须保证程序语义正确，而 Anti 和 Output 依赖是由于架构寄存器数量有限导致的。此外，还需处理长延迟操作和异常中断等情况。停顿是流水线运行中的常见问题，原因包括资源依赖（如寄存器文件、内存和功能单元的资源冲突）、数据依赖和控制依赖等，这些问题会导致流水线停止运行，影响处理器性能，需要通过相应的技术手段加以解决。
    - **数据依赖处理策略**：针对数据依赖问题，有多种处理方法。Anti 和 Output 依赖相对较易处理，可通过在最后阶段按程序顺序写入目的地来解决。对于 Flow 依赖，有五种基本处理方式：一是检测并等待数据在寄存器文件中可用；二是在软件层面检测并消除依赖，无需硬件检测；三是检测并通过转发或旁路数据给相关指令，其核心思想是在结果产生后直接将数据送到需要的功能部件，而非经过寄存器文件，实现时需要增加依赖检查逻辑、数据转发路径和冲突检测电路来控制选通器；四是预测所需值并进行推测执行，然后验证结果；五是采用细粒度多线程技术，无需检测依赖。这些方法各有优缺点，在实际应用中需要根据具体情况选择合适的策略来优化流水线性能。
</br>

## L3-复杂流水线和乱序执行(中)
### （一）流水线停顿因素
在计算机体系结构中，流水线停顿是影响处理器性能的关键因素，以下对其原因进行详细讲解：
1. **资源依赖**：当计算机硬件资源（如运算单元、存储单元等）不能满足同时执行多条指令的需求时，就会出现资源依赖导致的流水线停顿。例如，在一个只有一个浮点乘法器的系统中，如果有多条浮点乘法指令连续进入流水线，后续的浮点乘法指令就必须等待前一条指令完成对浮点乘法器的使用后才能继续执行，这种等待会使流水线暂时停止流动，降低了指令执行的效率。就好像一条单车道的道路上，多辆车需要依次通过一个狭窄的路段，后面的车只能等待前面的车通过后才能前行。
2. **数据依赖**
    - **真数据相关（RAW）**：这是一种常见的数据依赖形式。例如，在指令序列中，一条加法指令 ADD R1, R2, R3（将寄存器 R2 和 R3 的值相加并存入 R1）后面跟着一条乘法指令 MUL R4, R1, R5（使用 R1 的值与 R5 相乘并存入 R4），这里乘法指令需要读取加法指令写入 R1 的结果，这种写后读的关系就是真数据相关。如果加法指令还未完成对 R1 的写入，乘法指令就不得不停顿等待，以确保读取到正确的数据，否则会导致计算错误。这就如同一个工人需要使用另一个工人刚刚生产出来的零件才能继续工作，如果零件还没准备好，工人就只能暂停。
    - **反相关（WAR）**：以如下指令序列为例，指令一为 SUB R6, R7, R8（将寄存器 R7 和 R8 的值相减并存入 R6），指令二为 AND R9, R6, R10（使用 R6 的值与 R10 进行与运算并存入 R9），这里指令二需要读取 R6 的值，而指令一在执行过程中会写入 R6。如果不进行特殊处理，当指令二先于指令一执行到读取 R6 的阶段时，就会读取到错误的数据，从而引发数据冲突，导致流水线停顿。这类似于两个人同时需要使用同一个工具，一个人正在使用时，另一个人必须等待，否则会出现问题。
    - **输出相关（WAW）**：比如有两条指令，指令一为 ADD R11, R12, R13（将寄存器 R12 和 R13 的值相加并存入 R11），指令二为 OR R11, R14, R15（使用 R14 和 R15 的值进行或运算并存入 R11），这两条指令都要向 R11 写入结果。如果不加以控制，后执行的指令可能会覆盖先执行指令写入 R11 的正确结果，导致数据错误，因此在这种情况下流水线需要停顿以保证数据的正确性。这就好像两个人同时往同一个箱子里放东西，后放的可能会把先放的东西覆盖掉。
3. **控制依赖**：在程序执行过程中，分支指令起着关键的控制作用。例如在一个 if - else 语句中，分支指令判断条件后决定程序是执行 if 分支还是 else 分支的指令。如果后续的指令依赖于这个分支的结果，那么这些指令就不能在分支指令之前执行，否则会改变程序的逻辑。而且，如果分支预测不准确，处理器可能已经预取了错误分支的指令并进入流水线，当发现分支预测错误时，就需要清空流水线中错误分支的指令，重新取正确分支的指令，这就会导致流水线停顿，严重影响处理器的性能。就像在一个岔路口，车辆必须等待交通信号灯的指示才能确定前进的方向，如果提前进入错误的道路，就需要返回重新选择，从而耽误时间。 

### （二）指令调度策略
以下是对指令调度策略第二部分内容的详细讲解：
1. **静态调度流程**
    - 编译器在静态调度中起着核心作用。它会对整个程序的指令序列进行全面分析，识别出指令之间存在的各种依赖关系，包括数据依赖和控制依赖等。例如在一个循环结构中，可能存在一些计算操作和数据加载操作。编译器会通过分析发现哪些指令之间不存在数据依赖，然后将这些数据无关的指令提前执行。比如在一个简单的数组求和循环中，有计算数组元素地址的指令和将数组元素累加到总和的指令。编译器可以先安排地址计算指令提前执行，因为它们与累加操作在数据上没有直接关联。通过这样的调整，使得相互依赖的指令在时间上间隔增大。这样做的目的是减少因指令依赖而导致的流水线停顿。然而，这种方法存在明显的局限性。编译器开发人员必须对目标流水线的结构设计有深入了解，包括有多少个功能部件、每个功能部件的执行延迟（latency）是多少等信息。因为不同的流水线结构可能对指令调度有不同的要求，如果编译器不能准确适配，就无法达到最佳的调度效果。而且，这种静态调度的通用性较差，对于每一款不同的 CPU，可能都需要开发专门的编译器。因为不同 CPU 的流水线结构、功能部件等可能存在差异。此外，一旦出现新的 CPU 型号，为了让应用程序在新 CPU 上获得较好的性能，就需要重新编译所有的应用程序，这无疑增加了软件开发和维护的成本。另外，静态调度受 cache miss 的影响很大。由于编译器在编译时无法预先知道哪一次 load 操作会导致 cache miss，所以当 cache miss 发生时，必然会导致流水线停顿，而这种停顿很难通过静态调度的方式来有效解决。
2. **动态调度机制**
    - **ID 阶段改造**：动态调度对传统的 ID（Instruction Decode，指令译码）阶段进行了重要改造，将其拆分为 Issue 和 Read operands 两个阶段。在 Issue 阶段，主要进行精简的操作，包括指令译码和资源冲突检测等基本任务。这个阶段仍然保持按序执行的特性，这是为了确保指令执行的顺序性和可预测性。但与传统的 ID 阶段不同的是，它不再对所有的数据冲突进行检测。这样做的好处是，即使指令存在一些潜在的数据冲突，只要满足其他条件，如没有资源冲突，这些指令也有机会被发射出去，进入后续的执行流程，从而提高了指令发射的灵活性。而在 Read operands 阶段，其主要职责是检测数据冲突。这个阶段是乱序执行实际发生的关键位置。当指令的操作数准备就绪时，即不存在数据冲突，该指令就可以直接投入运行，实现乱序执行，从而提高了指令执行的并行性。而对于那些操作数尚未就绪的非就绪指令，则会在这个阶段停顿，等待操作数就绪后再继续执行。例如，假设有两条指令，一条是 ADD 指令，其操作数已经在寄存器中且没有其他指令占用相关资源，那么这条 ADD 指令在经过 Issue 阶段后，在 Read operands 阶段会被判断为就绪指令，可以立即投入执行。而如果另一条 MUL 指令的操作数需要等待前一条指令的计算结果，那么在 Read operands 阶段，MUL 指令就会停顿，直到其操作数就绪。
    - **就绪指令判断**：判断一条指令是否为就绪指令的关键标准是无资源冲突且操作数就绪。以 ADD 指令为例，如果 ADD 指令所需的操作数已经存储在寄存器中，并且没有其他正在执行的指令占用与这些操作数相关的资源，比如没有其他指令正在对这些寄存器进行写操作，那么这条 ADD 指令就被认为是就绪指令，可以进入执行阶段。这种判断方式为动态调度提供了基础，使得处理器能够在运行时根据指令的实际情况灵活地调整执行顺序，充分利用硬件资源，提高指令执行的效率和并行性，减少因等待资源或数据而导致的流水线停顿。 

### （三）计分板算法运行
以下是对计分板算法运行部分内容的详细讲解：
1. **指令执行过程**
    - **Issue 阶段操作**：在这个阶段，计分板首先会检查各个功能单元的状态，判断是否有空闲的功能单元可供指令使用。同时，还会查看是否有其他指令正在写相同的目的寄存器。例如，当有一条加载指令（如 L.D）需要执行时，计分板会检查整数单元是否处于空闲状态，并且没有其他指令正在对该加载指令的目的寄存器进行写操作。如果满足这两个条件，那么这条加载指令就可以被发射到整数单元中，并同时更新计分板内部的数据结构，记录下该指令已被发射到的功能单元等相关信息。这就好比在一个工厂的生产线上，新的任务（指令）要分配到某个工作站（功能单元），需要确保该工作站有空余并且不会与其他正在进行的任务产生冲突。
    - **Read operands 检测**：计分板会持续监测指令的源操作数情况。对于每一条指令，它会检查其源操作数是否被更早的指令写入且尚未完成写入操作。比如某条指令的源操作数是 R1，如果之前有一条指令正在对 R1 进行写操作且还未结束，那么这条指令在 Read operands 阶段就会停顿，等待 R1 被正确写入后才能继续执行。这是为了确保指令读取到的操作数是正确的、最新的。可以想象成一个工人在等待另一个工人完成对某个工具（寄存器）的准备工作后才能使用这个工具进行自己的任务。
    - **Execute 与 Write result 步骤**：当指令的操作数准备就绪后，功能单元就会接收这些操作数并开始执行指令的运算操作。在功能单元完成执行后，它会通知计分板，表示该指令已经执行完毕。此时，计分板会进行 WAR（Write After Read）冲突的检查。如果不存在 WAR 冲突，那么指令就可以将结果写入到目的寄存器中。例如，一条加法指令 ADD 在执行完后，计分板会检查是否有其他指令在读取该加法指令的目的寄存器，如果没有，加法指令就可以顺利写入结果。这个过程就像生产线上的产品加工完成后，需要经过质量检查（冲突检查）才能进入下一个环节（写入结果）。
2. **算法性能局限**
    - **控制冲突处理问题**：计分板算法的一个重要局限是它不能有效地处理控制冲突。在程序执行过程中，分支指令会改变指令的执行顺序，而计分板算法无法对这种情况进行很好的应对。它的乱序执行仅仅局限在一个基本块内，无法跨越基本块进行指令的动态调度。这意味着当遇到分支指令时，计分板算法可能无法充分利用处理器的资源来提高执行效率，因为它不能提前处理分支指令后面的指令，可能会导致流水线停顿等待分支结果。例如在一个包含 if - else 结构的程序中，计分板算法可能无法在分支指令执行前就合理安排 if 和 else 分支中的指令执行顺序，从而降低了整体性能。
    - **数据冲突导致停顿**：另一个性能局限是计分板算法仍然存在 WAR 和 WAW（Write After Write）冲突导致的停顿问题。尽管它在一定程度上对数据依赖进行了管理，但对于 WAR 和 WAW 冲突，它的处理方式往往是通过停顿流水线来避免错误的发生。例如在某些情况下，当存在 WAR 冲突时，后续的指令可能会因为等待前面指令完成对寄存器的读取而停顿，即使其他资源是空闲的。这种停顿会浪费处理器的时钟周期，降低指令执行的吞吐量，影响整个系统的性能表现。 

### （四）Tomasulo 算法细节
以下是对 Tomasulo 算法细节部分内容的详细讲解：
1. **关键结构功能**
    - **保留站作用**：
        - 保留站在 Tomasulo 算法中起着至关重要的缓冲和调度作用。它负责缓存即将执行的指令以及这些指令所需的操作数。当一条指令进入保留站时，如果其操作数已经就绪，那么这些操作数就会被缓存到保留站中，等待被发送到相应的功能部件执行。例如，对于一条加法指令 ADD R1, R2, R3，当 R2 和 R3 的值已经准备好时，它们会和 ADD 指令一起被存储在保留站中。
        - 然而，如果操作数尚未就绪，保留站就会监听公共数据总线（CDB）。因为其他功能部件执行完指令后会将结果通过 CDB 广播，保留站通过监听 CDB，一旦发现自己所需的操作数在 CDB 上出现，就会获取并缓存该操作数。例如，假设另一条乘法指令 MUL R4, R5, R6 先执行，其结果要作为后续某条指令的操作数，那么这条后续指令所在的保留站就会在 CDB 上等待并获取 MUL 指令的结果。
        - 每个功能部件都有独立的保留站，这保证了不同类型的指令可以在各自的保留站中进行排队和调度。当某个功能部件的保留站已满时，新的指令就无法发射到该保留站，只能等待有空位出现，这确保了功能部件不会因接收过多指令而导致混乱。
    - **公共数据总线（CDB）**：
        - CDB 是整个系统中数据传输和共享的关键通道。它负责将功能部件执行完指令后的结果广播到所有的保留站和寄存器中。例如，当一个浮点加法功能部件完成了一条加法指令的执行并得到结果后，会通过 CDB 将这个结果发送出去。
        - 在广播结果的同时，会附带生产该结果的指令所在保留站的行号标签。这个标签非常重要，它使得接收结果的保留站和寄存器能够准确地识别该结果是否是自己所需要的。比如，某个保留站中的指令正在等待来自特定保留站的操作数，当 CDB 上出现带有相应标签的结果时，它就知道这是自己需要的操作数，可以进行接收和缓存，从而实现了数据的前送和结果的准确匹配，避免了数据传输的错误和混乱。
    - **寄存器重命名原理**：
        - 寄存器重命名是 Tomasulo 算法消除 WAR/WAW 冲突的核心机制。它通过给每个要产生的值分配一个独特的 tag，并利用重命名映射表（RAT）来维护这些 tag 和寄存器之间的关系。例如，当一条指令要向某个寄存器写入一个新值时，它会在 RAT 中为这个寄存器分配一个新的 tag，这个 tag 指向产生该值的保留站或其他数据源。
        - 当其他指令需要读取这个寄存器的值时，它们不会直接从寄存器中读取，而是通过查询 RAT 找到对应的 tag，然后根据 tag 去获取正确的值源。比如，有两条指令，指令一写寄存器 R1，指令二读寄存器 R1，在 Tomasulo 算法下，指令二会根据 RAT 找到指令一为 R1 分配的 tag，从而获取到指令一产生的正确值，而不是直接读取可能已经被指令一更新前的 R1 值，这样就有效地消除了 WAR/WAW 冲突。
2. **算法执行流程**：
    - 首先，在指令发射阶段，如果有可用的保留站，那么新的指令以及经过重命名的操作数就会被插入到保留站中。这里的重命名操作数是根据寄存器重命名机制进行处理后的操作数，确保了数据的正确来源。如果没有可用的保留站，指令就会停顿，等待保留站有空闲位置。例如，当系统中有多个指令同时到达发射阶段，而部分保留站已满时，那些无法进入保留站的指令就会处于等待状态。
    - 进入保留站后的指令会持续监听 CDB，以获取自己所需的操作数。一旦指令的所有操作数都在 CDB 上获取到并就绪，该指令就会被发送到相应的功能部件进行执行。比如，一条乘法指令在保留站中等待两个操作数，当这两个操作数分别通过 CDB 从其他功能部件的执行结果中获取到后，乘法指令就可以被发送到浮点乘法功能部件进行运算。
    - 当功能部件完成指令的执行后，会将执行结果通过 CDB 进行广播。同时，寄存器会根据 CDB 上结果附带的标签来判断是否接收该结果。如果寄存器对应的标签与 CDB 上广播结果的标签匹配，那么寄存器就会将该结果写入，完成整个指令的执行流程，实现了数据的高效传输和指令的正确执行，提高了处理器的性能和并行性。 
</br>

## L4-复杂流水线和乱序执行(下)
### 1. 多周期执行相关问题
在计算机体系结构中，多周期执行是一个重要的概念，它带来了一系列的特点和问题：
- **指令执行时间差异**：在多周期执行模式下，不同的指令在执行阶段所需要的时间是不一样的。例如整数加法（Integer add）和整数乘法（Integer mul）、浮点乘法（FP mul）以及加载/存储（Load/store）等指令，它们在执行时可能会因为操作的复杂程度不同而花费不同的时钟周期数。这是由于不同的运算逻辑和硬件实现方式导致的，像浮点乘法通常比整数加法更为复杂，所以其执行周期可能更长。
- **对指令顺序语义的影响**：这种执行方式虽然允许独立的指令在之前长延迟指令完成之前就在不同的功能单元开始执行，这在一定程度上提高了处理器的并行性和效率。但是，它却破坏了指令集架构（ISA）的顺序语义。因为按照 ISA 的设计初衷，指令是应该按照程序编写的顺序依次执行并产生相应结果的。而多周期执行可能导致指令的执行顺序与程序顺序不一致，从而引发一些潜在的问题。
- **异常处理的复杂性**：在多周期执行过程中，异常处理变得更加复杂。异常被定义为程序执行过程中 CPU 遇到的特殊情况，分为内部“异常”和外部“中断”。内部“异常”如硬故障中断（像电源掉电、硬件线路故障等）和程序性中断（如算术溢出、缺页、越界、越权、非法指令、除数为 0、堆栈溢出、访问超时、断点设置、单步、系统调用等），这些异常是在 CPU 内部发生的。外部“中断”则是在 CPU 外部发生的特殊事件，通过“中断请求”信号向 CPU 请求处理，如实时钟、控制台、打印机缺纸、外设准备好、采样计时到、DMA 传输结束等。乱序执行容易引发不精确异常，即异常产生时的处理器状态与指令按严格程序顺序执行时不完全相同。这是因为流水线可能已经完成了程序顺序比引起异常的指令靠后的指令，或者还未完成程序顺序比引起异常的指令靠前的指令。
- **保证精确异常的方法**：为了确保精确异常，有两种主要的思路。一种是使每个操作都花费相同的时间，这样可以保证指令的执行顺序和异常处理都能符合 ISA 的顺序语义。然而，这种方法的缺点是会增加指令的延迟，因为所有指令都要按照最长执行时间的指令来进行同步。例如，如果有一个非常耗时的操作，那么其他原本可以快速执行的指令也不得不等待相同的时间，这就降低了整体的执行效率。另一种方法是采用一些辅助技术，如历史缓冲区、未来寄存器文件、检查点等。历史缓冲区可以记录指令的执行历史信息，以便在异常发生时能够恢复到正确的状态；未来寄存器文件可以提前保存一些可能会被后续指令使用的数据，避免因为异常而丢失；检查点则是在特定的执行点保存处理器的状态，当出现异常时可以快速回滚到检查点状态进行处理。

### 2. 重排序缓冲（ROB）
重排序缓冲（ROB）在计算机体系结构中起着关键作用：
- **指令重排序与状态更新机制**
    - ROB 允许在指令提交前进行重排序，这是提升处理器性能的重要手段。在指令执行过程中，当指令完成执行时，会先更新寄存器别名表（RAT），RAT 可看作是前端寄存器文件，用于记录指令执行过程中的寄存器映射关系，确保指令间数据的正确传递和操作。而只有当指令退休时，也就是成为机器中最老且已完成执行的指令时，才会更新架构寄存器文件，这样就保证了架构状态始终按照程序顺序进行精确更新，避免因乱序执行导致的状态不一致问题。例如，在执行一系列指令时，可能有多条指令同时处于执行阶段，但它们完成的先后顺序可能与程序顺序不同，ROB 确保了最终对架构寄存器文件的更新是有序的，符合程序的逻辑顺序。
- **ROB 记录信息的全面性**
    - ROB 记录了丰富的信息，这些信息对于指令的正确执行和异常处理至关重要。它包含目标寄存器 ID 和值，这有助于确定指令的操作结果应该存储到哪个寄存器以及具体的值是多少；目标存储器地址和值，用于处理与存储器相关的操作，如加载和存储指令；指令 PC，方便在需要时回溯指令的执行位置；寄存器/数据有效位，用于判断数据是否已经准备好，避免使用未就绪的数据进行操作；控制位，控制指令的执行流程和相关操作；异常标志位，能够及时标记指令执行过程中是否出现异常情况。例如，在执行一条加法指令时，ROB 会记录目标寄存器（假设为 R1）的 ID，以及计算得到的结果值，同时设置相应的有效位表示结果已就绪，若在执行过程中发生溢出等异常，异常标志位会被置位，后续处理流程可以根据这些信息进行相应操作。
- **操作原则的重要性**
    - ROB 的操作遵循按序分发/执行、乱序完成、按序退休原则。按序分发/执行确保了指令按照程序顺序进入执行阶段，维持了程序的基本逻辑顺序。乱序完成则利用了处理器的并行性，允许指令在不影响最终结果的前提下，根据资源可用性和执行时间的不同，以乱序的方式完成执行，提高了执行效率。而按序退休是保证架构状态精确性的关键环节，它使得指令对架构寄存器文件和内存的更新是按照程序顺序进行的，避免了因乱序更新可能带来的错误。例如，在一个循环结构中，多条指令可能在不同的时钟周期内完成执行，但只有最老的指令按照顺序退休并更新架构状态，这样就保证了循环执行过程中数据的一致性和正确性。

### 3. 寄存器重命名
在计算机体系结构中，寄存器重命名是提升处理器性能的关键技术之一，以下是对这部分内容的详细讲解：
- **Tomasulo 算法的局限性**
    - Tomasulo 算法在数据传输和硬件结构方面存在明显的性能局限。在数据总线方面，由于大量的数据需要在公共数据总线上进行传输，例如运算结果、寄存器数据等，这导致了数据总线传输量过大。过多的数据传输会占用大量的总线带宽，使得数据传输的延迟增加，进而影响整个处理器的运行效率。同时，该算法中使用的多路复用器和长总线也会对时钟频率产生负面影响。多路复用器需要在多个输入数据中进行选择并输出，其复杂的逻辑操作会增加信号传输的延迟。长总线则会导致信号传输的时间变长，并且容易受到干扰，这些因素综合起来会降低处理器的时钟频率，限制了处理器的性能提升。
- **物理寄存器文件的应用**
    - 为了克服 Tomasulo 算法的局限性，采用了物理寄存器文件的方法。这种方法首先消除了原有的架构寄存器文件，因为架构寄存器文件在某些情况下可能会限制寄存器的灵活使用。然后添加了更大的物理寄存器文件，其容量远大于架构寄存器文件（例如可能从原来的 32 个架构寄存器扩展到数量远大于 32 的物理寄存器，如 P0 - Pn，n >> 32）。通过修改重命名表来建立架构寄存器与物理寄存器之间的映射关系，使得指令在执行过程中能够将目标寄存器重命名为物理寄存器。例如，一条指令原本要将结果写入架构寄存器 R1，经过重命名后会写入到对应的物理寄存器 Pi。同时，引入空闲列表来管理未分配的物理寄存器，当有新的指令需要寄存器资源时，可以从空闲列表中获取可用的物理寄存器进行分配。如果在执行过程中出现物理寄存器不足的情况，处理器可能会暂停流水线操作，等待有可用的物理寄存器后再继续执行。
- **寄存器重命名的实现方式**
    - 寄存器重命名可以通过两种方式实现，即缓冲标签和物理寄存器。在使用物理寄存器进行重命名时，指令的目标寄存器会被重命名为物理寄存器，并且在同一架构寄存器的下一次写操作提交之前，该物理寄存器不会被重新分配，只有当这次写操作完成提交后，才可以被重用。例如，对于一系列操作指令，如果第一条指令将结果写入物理寄存器 P1 并对应架构寄存器 R1，在后续的指令中，如果还有对 R1 的写操作未完成提交，那么 P1 就不会被分配给其他指令使用，直到该写操作完成。这种重用机制保证了数据的一致性和正确性，同时也提高了寄存器资源的利用率，减少了不必要的寄存器分配和释放操作，进一步提升了处理器的性能。 

### 4. 分支预测
在计算机体系结构中，分支预测是优化流水线处理器性能的关键环节，以下是对这部分内容的详细讲解：
- **分支指令带来的问题**：在流水线处理器的运行过程中，控制流指令（分支指令）的出现频率相当高，大约占所有指令的 15 - 25%。由于分支指令的执行结果会改变程序的执行流程，所以在流水线中确定其下一条取指地址时会存在明显的延迟。在传统的流水线操作中，需要等待分支指令执行完成并确定跳转方向后，才能明确下一条要取指的指令地址。而这个等待过程会导致流水线出现停顿，降低处理器的执行效率。如果发生分支预测错误，那么之前已经在流水线中预取和部分执行的指令都将作废，会造成大量的指令槽被浪费，严重影响处理器的性能。例如，在一个循环结构中，如果分支预测错误，可能会导致整个循环体的指令都需要重新取指和执行，极大地增加了执行时间。
- **处理控制依赖的方法**
    - **消除控制流指令**：谓词合并是将复杂的谓词条件转换为更简单的形式，通过将多个相关的条件判断合并为一个，减少分支指令的数量。例如，对于条件“(a == b) && (c < d) && (a > 5000)”，原本可能需要三条分支指令分别判断每个条件，通过谓词合并可以将其转换为一个综合的条件判断，只使用一条分支指令。谓词执行则是将控制依赖转换为数据依赖，编译器为每个指令设置一个谓词位，只有当谓词位为真时指令才会被执行，否则相当于执行一条空操作（NOP）指令，从而避免了分支指令的使用。
    - **分支预测**：这是一种通过猜测分支指令的执行结果来提前确定下一条取指地址的方法。在取指阶段就对分支指令的行为进行预测，包括分支是否会被执行（即分支方向）以及如果被执行，其目标地址是多少。如果预测准确，流水线可以继续流畅运行，避免停顿；如果预测错误，则需要进行回滚和重新取指等操作，但相比于不进行预测，仍然有可能提高整体性能。
    - **延迟分支**：在这种方法中，将分支指令后面的一条或多条指令放置在分支延迟槽中，无论分支是否跳转，这些延迟槽中的指令都会被执行。这样可以利用分支延迟的时间来执行一些有用的操作，减少因分支等待而造成的性能损失。例如，在一些简单的循环结构中，可以将循环体中的部分不依赖于分支结果的指令放置在延迟槽中，提高流水线的利用率。
    - **细粒度多线程**：通过在处理器中同时运行多个线程，当一个线程因为分支等待或其他原因停顿下来时，可以切换到其他就绪的线程继续执行，从而提高处理器的整体利用率。这种方法需要硬件对多线程的支持，包括线程切换机制、寄存器保存和恢复等功能。
    - **多路执行**：如果能够提前确定分支的多个可能路径的地址，处理器可以同时从多个可能的路径取指并执行指令，当分支结果确定后，再选择正确的执行路径继续执行，丢弃错误路径的执行结果。这种方法需要较多的硬件资源来支持多个路径的取指和执行，但在某些情况下可以显著提高性能。
- **分支预测的分类**
    - **简单预测**：总是预测下一条顺序指令是一种简单直接的预测方法。它假设程序大多数情况下是顺序执行的，所以直接将下一条取指地址预测为当前 PC + 4（假设指令长度为 4 字节）。这种方法在一些简单的程序中可能有一定的效果，但对于含有较多分支且分支行为复杂的程序，预测准确率较低。
    - **增强预测**：在取指阶段需要预测三个关键信息，即分支方向、是否为分支指令以及分支目标地址。分支目标缓冲器（BTB）在这个过程中起到了重要作用。BTB 的结构类似于 cache，它使用当前 PC 的低 k 位作为索引，取出一个表项，然后进行精确匹配，从而得到预测的 PC。通过保存之前分支指令的相关信息，BTB 可以快速提供分支目标地址的预测，帮助处理器提前确定取指方向。
- **分支方向预测的类型**
    - **静态预测**
      - **总是不 taken 和总是 taken**：总是不 taken 策略实现简单，不需要额外的硬件支持如 BTB 和方向预测，但对于条件分支的预测准确率较低，大约在 30 - 40%。而总是 taken 策略不需要进行方向预测，对于一些常见的如向后的分支（通常在循环结构中，目标地址低于分支 PC）有较好的预测效果，准确率约为 60 - 70%。
      - **BTFN（Backward taken, forward not taken）**：这种策略根据分支的方向特点进行预测，将向后的分支（通常是循环分支）预测为 taken，其他分支预测为 not taken，利用了循环结构中分支的常见行为模式。
      - **基于 profile 和基于程序分析**：基于 profile 的方法是编译器通过运行程序的一个样本，收集分支的执行情况信息，然后根据这些信息确定每个分支的可能执行方向，并将其编码为分支指令格式中的一个提示位。其准确性依赖于样本的代表性，如果样本能够很好地反映程序的实际运行情况，预测准确率会较高，但如果样本不具有代表性，准确率可能会很低。基于程序分析的方法则是利用一些启发式规则，例如根据操作码的特点（如预测 BLEZ 为 NT，因为在很多程序中负整数常被用作错误值）、循环结构的特点（预测保护循环执行的分支为 taken）以及指针和浮点比较的常见结果（预测不相等）等来确定分支的静态预测方向。这种方法不需要运行样本，但启发式规则可能并不适用于所有程序，需要编译器进行深入的分析并且依赖于指令集架构（ISA）的支持。
    - **动态预测**
      - **上次预测**：每个分支使用一个单比特来记录上次执行的方向，当下次遇到该分支时，直接根据这个比特的值进行预测。这种方法在循环结构中对于较大的循环次数（K）有较高的准确率，例如对于一个有 K 次迭代的循环，准确率为 (K - 2)/K，但对于循环次数较小的循环，准确率可能很低，甚至在某些情况下会总是预测错误（如循环只有 2 次迭代时）。
      - **基于 2 位计数器**：为每个分支关联一个 2 位计数器（存储在 BTB 中），相比单比特，多出来的一位提供了一定的滞后性。当分支连续两次执行结果相同时，才会改变预测结果，这样可以避免因为偶尔的一次不同结果而频繁改变预测方向，提高了预测的稳定性和准确性。例如，对于一个循环，其准确率可以达到 (K - 1)/K（假设计数器初始化为弱 taken），对于一些常见的分支行为模式有更好的预测效果，但需要更多的硬件资源来存储和更新这些计数器。
      - **两级预测**：包括全局分支相关和局部分支相关两种实现方式。全局分支相关是利用最近执行的其他分支的结果来预测当前分支的方向，例如，如果前一个分支未执行，那么下一个相关分支也很可能未执行。通过使用全局历史寄存器（GHR）来记录所有分支的执行历史，并使用这个历史信息作为索引来查找一个模式历史表（PHT），PHT 中存储了每个历史模式下分支的执行结果，从而进行预测。局部分支相关则是为每个分支设置一个独立的历史寄存器，记录该分支自身的执行历史，根据这个历史来预测分支的方向，同样使用 PHT 来存储和查找历史结果。这种两级预测方法结合了全局和局部的信息，能够更好地适应不同分支的行为特点，提高预测准确率。
      - **混合预测**：将多种不同的预测方法结合起来，根据不同的情况选择最合适的预测策略。例如，在某些情况下使用静态预测方法，在其他情况下使用动态预测方法，或者根据不同类型的分支选择不同的预测器。通过这种方式，可以综合利用各种预测方法的优势，进一步提高预测的准确性。
      - **基于神经网络**：利用神经网络的强大学习能力来进行分支预测，如感知机分支预测器。这种方法能够学习到复杂的分支行为模式，具有较高的预测精度，但需要更多的计算资源来进行神经网络的训练和推理，并且在硬件实现上也较为复杂。目前已经在一些处理器如 AMD Piledriver、AMD Ryzen 中得到应用。
- **其他相关预测器**
    - **锦标赛预测器**：考虑到不同分支指令与其他分支指令的相关性不同，有些分支使用全局历史进行预测效果好，而有些则使用局部历史预测更好。锦标赛预测器设置了两个预测器，一个基于全局历史，一个基于局部历史，同时还有一个选择器。选择器根据一定的规则（通常使用 PC 作为索引的一个小的预测器）来决定对于当前分支指令应该采用哪个预测器的结果。通过这种方式，锦标赛预测器能够在不同的分支情况下选择最合适的预测策略，从而获得较好的性能。在实际的性能测试中，锦标赛预测器通常比其他单一的预测器表现更好。
    - **BTB 和 BHT 结合**：在取指（IF）阶段，同时利用当前 PC 检索分支历史表（BHT）和分支目标缓冲器（BTB），但以 BHT 的结果为主。如果 BHT 预测分支跳转，并且 BTB 命中，则使用 BTB 中的预测 PC；如果 BTB 未命中，则会停顿等待。如果 BHT 预测不跳转，则直接使用 PC + 4 作为下一条取指地址（以 BHT 的预测为准）。BTB 和 BHT 的更新是在相应分支指令 commit 时进行，这样可以保证预测信息的准确性和及时性。
    - **返回地址预测器**：过程调用返回指令大约占所有分支指令的 15%左右，其特殊性在于每次返回的目标地址可能不同。直接使用 BTB 对返回地址进行预测效果不理想（准确率 < 60%），因为 BTB 中每条分支指令最多只保存一个目标地址。返回地址预测器通常使用栈来实现，当执行 Call 指令时，将返回地址 push 到栈中；当执行 Ret 指令时，从栈中 pop 一个返回地址作为预测的 PC。通过这种方式，可以准确地预测过程调用的返回地址，提高程序执行的效率。
</br>




















































































































































